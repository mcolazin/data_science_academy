{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e985510e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['o', 'gato', 'comeu', 'a', 'roupa', 'do', 'rei', 'de', 'roma']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence = \"o gato comeu a roupa do rei de roma\".split()\n",
    "sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8c1fb31a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'o': 0,\n",
       " 'gato': 1,\n",
       " 'comeu': 2,\n",
       " 'a': 3,\n",
       " 'roupa': 4,\n",
       " 'do': 5,\n",
       " 'rei': 6,\n",
       " 'de': 7,\n",
       " 'roma': 8}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab = {}\n",
    "for cod, token in enumerate(sentence):\n",
    "    vocab[token] = cod\n",
    "vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "46ae1f58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 2, 3, 4, 5, 6, 7, 8]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_transform = list(map(vocab.get, sentence)) # mapping for search token\n",
    "sentence_transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ce427ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A sentença acima , atualmente codificado em dicionario , pode ser representado numa matriz com one_hot_encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f26eefeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5c8a703c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 1.]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# com np.eye , ao criarmos uma matriz diagonal no comprimento do vocab (dicionario), este será sua representação one-hot\n",
    "np.eye(9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8c333fc6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 1, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 1, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 1, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 1, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 1, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 1, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 1, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 1]])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one_hot = np.eye(len(vocab), dtype= \"int\")\n",
    "one_hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "9a7fed4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 0, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Agora use a forma abaixo para endereçar  array apropriado:\n",
    "# palavra \"gato\"\n",
    "one_hot[vocab[\"gato\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "52847405",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 1, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one_hot[vocab[\"roupa\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "c13e63cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cos_similiarity(x,y): # distância entre vetores ou matrizes pela similaridade do Coseno\n",
    "    return (np.dot(x,y) / ( np.linalg.norm(x) * np.linalg.norm(x) ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "3f160d41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['o', 'gato', 'comeu', 'a', 'roupa', 'do', 'rei', 'de', 'roma']\n",
      "[[1 0 0 0 0 0 0 0 0]\n",
      " [0 1 0 0 0 0 0 0 0]\n",
      " [0 0 1 0 0 0 0 0 0]\n",
      " [0 0 0 1 0 0 0 0 0]\n",
      " [0 0 0 0 1 0 0 0 0]\n",
      " [0 0 0 0 0 1 0 0 0]\n",
      " [0 0 0 0 0 0 1 0 0]\n",
      " [0 0 0 0 0 0 0 1 0]\n",
      " [0 0 0 0 0 0 0 0 1]]\n",
      "{'o': 0, 'gato': 1, 'comeu': 2, 'a': 3, 'roupa': 4, 'do': 5, 'rei': 6, 'de': 7, 'roma': 8}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(None, None, None)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(sentence), print(one_hot), print(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "036bd5a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 0, 1, 0, 0, 0, 0, 0, 0]), array([0, 0, 0, 0, 1, 0, 0, 0, 0]))"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_1 = one_hot[vocab[\"comeu\"]]\n",
    "word_2 = one_hot[vocab[\"roupa\"]]\n",
    "word_1, word_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "848d579f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# distância da similaridade do Coseno entre word1 e word2\n",
    "cos_similiarity(word_1, word_2)\n",
    "# a distância do coseno entre arrays one-hot-encode é igual à ZERO. Assim cos_similiarity não é aplicável nesta situação.\n",
    "# sparse matrix não aceita este método de cálculo - devido a grande quantidade de zeros."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "a49c2dde",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.916, 0.158, 0.895, 0.964, 0.967],\n",
       "       [0.585, 0.593, 0.335, 0.054, 0.764],\n",
       "       [0.771, 0.149, 0.997, 0.264, 0.795],\n",
       "       [0.364, 0.472, 0.609, 0.116, 0.691],\n",
       "       [0.535, 0.822, 0.648, 0.765, 0.564],\n",
       "       [0.234, 0.33 , 0.839, 0.526, 0.026],\n",
       "       [0.37 , 0.739, 0.591, 0.714, 0.847],\n",
       "       [0.875, 0.343, 0.9  , 0.935, 0.221],\n",
       "       [0.956, 0.42 , 0.053, 0.67 , 0.943]])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# convertendo de sparse matrix para Dense Matrix\n",
    "# definindo um shape para o espaço vetorial:\n",
    "dim = 5\n",
    "#Criando o espaço vetorial com números randomicos\n",
    "W = np.random.rand(len(vocab), dim).round(3)\n",
    "W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "04c94c84",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.771, 0.149, 0.997, 0.264, 0.795])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Representação densa do array word_1 (\"comeu\")\n",
    "dense_word_1 = np.dot(word_1, W) # 1x9 e 9*5, saida = 1 * 5\n",
    "dense_word_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "36a9c5d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.535, 0.822, 0.648, 0.765, 0.564])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Representação densa do array word_2 (\"roupa\")\n",
    "dense_word_2 = np.dot(word_2, W)\n",
    "dense_word_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "e10b4dc2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 4)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# identficação dos index dos vetores na matriz:\n",
    "vocab[\"comeu\"], vocab[\"roupa\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "0028bfb9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.   , 0.   , 0.   , 0.   , 0.   ],\n",
       "       [0.   , 0.   , 0.   , 0.   , 0.   ],\n",
       "       [0.771, 0.149, 0.997, 0.264, 0.795],\n",
       "       [0.   , 0.   , 0.   , 0.   , 0.   ],\n",
       "       [0.535, 0.822, 0.648, 0.765, 0.564],\n",
       "       [0.   , 0.   , 0.   , 0.   , 0.   ],\n",
       "       [0.   , 0.   , 0.   , 0.   , 0.   ],\n",
       "       [0.   , 0.   , 0.   , 0.   , 0.   ],\n",
       "       [0.   , 0.   , 0.   , 0.   , 0.   ]])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# construindo uma matriz do espaço vetorial W, somente com as palavras densas word_1, word_2\n",
    "w_out_1_2 = np.zeros(shape = W.shape)\n",
    "w_out_1_2[2] = dense_word_1\n",
    "w_out_1_2[4] = dense_word_2\n",
    "w_out_1_2 # esta é a matrix parcialment densa somente com as palavras do vocab 2 e 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "8d82cb83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7919828643488159"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cálculo da distância entre word_2 e word_4:\n",
    "cos_similiarity(dense_word_1, dense_word_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0344799",
   "metadata": {},
   "source": [
    "### criando Matrix densa - WordEmbeddings with Pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "b0c237ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# a camada embbeding deve ser declarada como uma camada na rede neural Pytorch, assim:\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "4d8c07a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_layer = nn.Embedding(num_embeddings=9, embedding_dim=5, _weight=torch.FloatTensor(W) ) # matriz 9 X 5 - pesos aleatorios W\n",
    "idxes_tensor = torch.LongTensor([2,4])  # 2 e 4 são as posições das palavras comeu e roupa no indice original\n",
    "embeded = embed_layer(idxes_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "9a430bfa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[0.9160, 0.1580, 0.8950, 0.9640, 0.9670],\n",
       "        [0.5850, 0.5930, 0.3350, 0.0540, 0.7640],\n",
       "        [0.7710, 0.1490, 0.9970, 0.2640, 0.7950],\n",
       "        [0.3640, 0.4720, 0.6090, 0.1160, 0.6910],\n",
       "        [0.5350, 0.8220, 0.6480, 0.7650, 0.5640],\n",
       "        [0.2340, 0.3300, 0.8390, 0.5260, 0.0260],\n",
       "        [0.3700, 0.7390, 0.5910, 0.7140, 0.8470],\n",
       "        [0.8750, 0.3430, 0.9000, 0.9350, 0.2210],\n",
       "        [0.9560, 0.4200, 0.0530, 0.6700, 0.9430]], requires_grad=True)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embed_layer.weight # pesos aleatórios da matriz 9 words POR 5 cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "a6676a6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.7710, 0.1490, 0.9970, 0.2640, 0.7950],\n",
       "        [0.5350, 0.8220, 0.6480, 0.7650, 0.5640]],\n",
       "       grad_fn=<EmbeddingBackward0>)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeded # palavras 2 e 4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "8c0a6772",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.7967, grad_fn=<DivBackward0>)"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculando as distancias entre as palavras 2 e 4:\n",
    "F.cosine_similarity(embeded[0], embeded[1], dim=0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
